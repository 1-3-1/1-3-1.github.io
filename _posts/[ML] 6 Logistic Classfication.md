[**](/)

ğŸ·-ğŸ¹-ğŸ· {.site-title}
=====

**

**

-   [**â˜¾ ğ™·ğš˜ğš–ğš](/)
-   [**â˜¾ ğ™²ğšŠğšğšğšğš˜ğš›ğš’ğšğšœ](/categories/)
-   [**â˜¾ ğšƒğšŠğšğšœ](/tags/)
-   [**â˜¾ ğ™°ğš›ğšŒğš‘ğš’ğšŸğšğšœ](/archives/)
-   **Search

**

**

**

** 0%

[ML] 6 Logistic Classification {.post-title itemprop="name headline"}
==============================

** Posted on 2020-09-03 ** In [Study](/categories/Study/) ,
[ML](/categories/Study/ML/)

[](#Logistic-Classificationì´ë€ "Logistic Classificationì´ë€")Logistic Classificationì´ë€ {#Logistic-Classificationì´ë€}
-----------------------------------------------------------------------------------------

ë‘˜ ì¤‘ì— í•˜ë‚˜ë¥¼ ê³ ë¥´ëŠ” ê²ƒ. ì˜ˆë¥¼ë“¤ë©´ ìŠ¤íŒ¸ì¸ì§€ ì•„ë‹Œì§€. ë˜ëŠ” í˜ì´ìŠ¤ë¶ í”¼ë“œ.
ì„ ë³„í•´ì„œ ì¬ë°Œê³  ì¢‹ì€ê±°ë§Œ ë³´ì—¬ì¤Œ. ê³ ë¡œ ê²°ê³¼ê°€ 0ê³¼ 1 ì¤‘ í•˜ë‚˜ë¡œ
ë‚˜íƒ€ë‚´ì–´ì ¸ì•¼í•œë‹¤

### [](#Logistic-Hypothesis "Logistic Hypothesis")Logistic Hypothesis {#Logistic-Hypothesis}

logistic hypothesisëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë‚˜íƒ€ë‚´ì–´ì§„ë‹¤\
`H(X) = 1/ 1+e^(-W^T*X)`

ì´ í•¨ìˆ˜ëŠ” ë¬´ì¡°ê±´ 0 ì•„ë‹ˆë©´ 1ë¡œ ìˆ˜ë ´í•˜ê²Œ ëœë‹¤.

### [](#Cost-function "Cost function")Cost function {#Cost-function}

C( H(x),y ) = ylog(H(x)) - (1-y)log(1-H(x))\
yê°€ 1ì¼ ë•ŒëŠ” ë’¤ì— ìˆëŠ” í•­ì´ ì—†ì–´ì§€ê³  yê°€ 0ì¼ ë•ŒëŠ” ì•ì— ìˆëŠ” í•­ì´
ì—†ì–´ì§„ë‹¤

[](#ì‹¤ìŠµ "ì‹¤ìŠµ")ì‹¤ìŠµ
--------------------

+--------------------------------------+--------------------------------------+
|     12345678910111213141516171819202 |     import tensorflow as tfx_data =  |
| 122232425262728293031323334353637383 | [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2] |
| 94041424344454647                    | ] # xê°’ì´ 2ê°œy_data = [[0],[0],[0],[1], |
|                                      | [1],[1]]X = tf.placeholder(tf.float3 |
|                                      | 2, shape=[None, 2])# ë“¤ì–´ì˜¤ëŠ” xê°’ì˜ ê°¯ìˆ˜Y =  |
|                                      | tf.placeholder(tf.float32, shape=[No |
|                                      | ne, 1])# ë‚˜ê°€ëŠ” yê°’ì˜ ê°¯ìˆ˜W = tf.Variable(t |
|                                      | f.random_normal([2,1]), name = 'weig |
|                                      | ht')# xê°’ì´ 2ê°œ, yê°’ì´ 1ê°œb = tf.Variable( |
|                                      | tf.random_normal([1]),name='bias')#  |
|                                      | logistic hypothesishypothesis = tf.s |
|                                      | igmoid(tf.matmul(X,W)+b)# cost funct |
|                                      | ioncost = -tf.reduce_mean(Y* tf.log( |
|                                      | hypothesis) + (1-Y) * tf.log(1-hypot |
|                                      | hesis))train = tf.train.GradientDesc |
|                                      | entOptimizer(learning_rate=0.01).min |
|                                      | imize(cost)predicted = tf.cast(hypot |
|                                      | hesis > 0.5, dtype=tf.float32)#0.5ë³´ë‹¤ |
|                                      |  í¬ë©´ 1 (true) ì‘ìœ¼ë©´ 0 (false)accuracy = |
|                                      |  tf.reduce_mean(tf.cast(tf.equal(pre |
|                                      | dicted, Y),dtype=tf.float32))with tf |
|                                      | .Session() as sess:    sess.run(tf.g |
|                                      | lobal_variables_initializer())    fo |
|                                      | r step in range(10001):        cost_ |
|                                      | val, _ = sess.run([cost, train], fee |
|                                      | d_dict={X: x_data, Y: y_data})       |
|                                      |   if step % 200 == 0:            pri |
|                                      | nt(step, cost_val)    h,c,a = sess.r |
|                                      | un([hypothesis ,predicted,accuracy], |
|                                      | feed_dict={X: x_data, Y: y_data})    |
|                                      |  print("\nHypothesis: ", h,"\nCorrec |
|                                      | t (Y):", c, "\nAccuracy: ",a)# hypot |
|                                      | hesisëŠ” ê³„ì‚°í•œ ê°’. 0.8 , 0.9 ...# predict |
|                                      | edëŠ” 1, 0 ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê°’. 19ë²ˆì§¸ì¤„# accuracyëŠ”  |
|                                      | ì˜ˆì¸¡í•œ ê°’ê³¼ ì •ë‹µ ê°’ì„ ë¹„êµí•´ì„œ ë§ëŠ”ì§€ í‹€ë¦°ì§€ ì¶œë ¥ |
+--------------------------------------+--------------------------------------+

[](#csv-íŒŒì¼ì„-ë¶ˆëŸ¬ì™€-ì˜ˆì¸¡í•˜ëŠ”-ì‹¤ìŠµ "csv íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ ì˜ˆì¸¡í•˜ëŠ” ì‹¤ìŠµ")csv íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ ì˜ˆì¸¡í•˜ëŠ” ì‹¤ìŠµ
-----------------------------------------------------------------------------------------------------

ì˜ˆë¥¼ ë“¤ì–´ ë‹¹ë‡¨ì— ëŒ€í•´ ë‹¹ë‡¨ë¥¼ ê²°ì •í•˜ëŠ” ë³€ìˆ˜ê°€ x1 \~ x3 ê¹Œì§€ìˆê³ , ë‹¹ë‡¨ë³‘ì˜
ìœ ë¬´ë¥¼ yë¡œ ë‚˜íƒ€ë‚¸ë‹¤ê³  í• ë•Œ,( 1ì´ë©´ ê±¸ë¦°ê±° 0ì´ë©´ ì•ˆê±¸ë¦°ê±°) ë‹¤ìŒê³¼ ê°™ì€
csv ìë£Œê°€ ìˆë‹¤ê³  ê°€ì •í•˜ê³  ì‹¤ìŠµí•´ë³´ì.

`doctor.csv`\
x1 | x2 | x3 | y\
123| 142|412|0\
13| 422|423|0\
83| 2142|532|1

+--------------------------------------+--------------------------------------+
|     12345678910111213141516171819202 |     import tensorflow as tfxy = np.l |
| 122232425262728293031323334353637383 | oadtxt('doctor.csv', delimiter=',',  |
| 940414243444546                      | dtype=np.float32)x_data = xy[:,0:-1] |
|                                      |  # x1,x2,x3 ì†ì„±ë§Œ ê°€ì ¸ì˜´y_data = xy[:,[-1 |
|                                      | ]] # yì†ì„±ë§Œ ê°€ì ¸ì˜´X = tf.placeholder(tf.f |
|                                      | loat32, shape=[None, 3])# ë“¤ì–´ì˜¤ëŠ” xê°’ì˜ ê°¯ |
|                                      | ìˆ˜Y = tf.placeholder(tf.float32, shap |
|                                      | e=[None, 1])# ë‚˜ê°€ëŠ” yê°’ì˜ ê°¯ìˆ˜W = tf.Varia |
|                                      | ble(tf.random_normal([3,1]), name =  |
|                                      | 'weight')# xê°’ì´ 3ê°œ, yê°’ì´ 1ê°œb = tf.Vari |
|                                      | able(tf.random_normal([1]),name='bia |
|                                      | s')# logistic hypothesishypothesis = |
|                                      |  tf.sigmoid(tf.matmul(X,W)+b)# cost  |
|                                      | functioncost = -tf.reduce_mean(Y* tf |
|                                      | .log(hypothesis) + (1-Y) * tf.log(1- |
|                                      | hypothesis))train = tf.train.Gradien |
|                                      | tDescentOptimizer(learning_rate=0.01 |
|                                      | ).minimize(cost)predicted = tf.cast( |
|                                      | hypothesis > 0.5, dtype=tf.float32)# |
|                                      | 0.5ë³´ë‹¤ í¬ë©´ 1 (true) ì‘ìœ¼ë©´ 0 (false)accur |
|                                      | acy = tf.reduce_mean(tf.cast(tf.equa |
|                                      | l(predicted, Y),dtype=tf.float32))wi |
|                                      | th tf.Session() as sess:    sess.run |
|                                      | (tf.global_variables_initializer())  |
|                                      |    for step in range(10001):         |
|                                      | cost_val, _ = sess.run([cost, train] |
|                                      | , feed_dict={X: x_data, Y: y_data})  |
|                                      |        if step % 200 == 0:           |
|                                      |   print(step, cost_val)    h,c,a = s |
|                                      | ess.run([hypothesis ,predicted,accur |
|                                      | acy],feed_dict={X: x_data, Y: y_data |
|                                      | })    print("\nHypothesis: ", h,"\nC |
|                                      | orrect (Y):", c, "\nAccuracy: ",a)#  |
|                                      | hypothesisëŠ” ê³„ì‚°í•œ ê°’. 0.8 , 0.9 ...# pr |
|                                      | edictedëŠ” 1, 0 ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê°’. 19ë²ˆì§¸ì¤„# accur |
|                                      | acyëŠ” ì˜ˆì¸¡í•œ ê°’ê³¼ ì •ë‹µ ê°’ì„ ë¹„êµí•´ì„œ ë§ëŠ”ì§€ í‹€ë¦°ì§€ ì¶œë ¥ |
+--------------------------------------+--------------------------------------+

[\# study](/tags/study/) [\# ML](/tags/ML/) [\# python](/tags/python/)

[** [pwnable.kr] bof
í’€ì´](/2020/09/02/%5Bpwnable.kr%5D%20bof%20%ED%92%80%EC%9D%B4/ "[pwnable.kr] bof í’€ì´")

[[ML] 7 Softmax Regression
**](/2020/09/03/%5BML%5D%207%20Softmax%20Regression/ "[ML] 7 Softmax Regression")

-   Table of Contents
-   Overview

1.  [1. Logistic
    Classificationì´ë€](#Logistic-Classification%EC%9D%B4%EB%9E%80)
    1.  [1.1. Logistic Hypothesis](#Logistic-Hypothesis)
    2.  [1.2. Cost function](#Cost-function)

2.  [2. ì‹¤ìŠµ](#%EC%8B%A4%EC%8A%B5)
3.  [3. csv íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ ì˜ˆì¸¡í•˜ëŠ”
    ì‹¤ìŠµ](#csv-%ED%8C%8C%EC%9D%BC%EC%9D%84-%EB%B6%88%EB%9F%AC%EC%99%80-%EC%98%88%EC%B8%A1%ED%95%98%EB%8A%94-%EC%8B%A4%EC%8A%B5)

![ğŸ·-ğŸ¹-ğŸ·](/images/avatar.gif)

ğŸ·-ğŸ¹-ğŸ·

[15 ğ™¿ğš˜ğšœğšğšœ](/archives)

[4 ğ™²ğšŠğšğšğšğš˜ğš›ğš’ğšğšœ](/categories/)

[7 ğšƒğšŠğšğšœ](/tags/)

[**ğš’ğš›ğš˜ğš—ğš›ğšŠğš’ğš—ğŸ¹ğŸº@ğšğš–ğšŠğš’ğš•.ğšŒğš˜ğš–](/ironrain34@gmail.com "ğš’ğš›ğš˜ğš—ğš›ğšŠğš’ğš—ğŸ¹ğŸº@ğšğš–ğšŠğš’ğš•.ğšŒğš˜ğš– â†’ ironrain34@gmail.com")

Â© 2020 ** ğŸ·-ğŸ¹-ğŸ·

Powered by [Hexo](https://hexo.io/) &
[NexT.Muse](https://muse.theme-next.org/)
